{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-01T13:44:04.014284Z",
     "start_time": "2018-04-01T13:44:03.293233Z"
    },
    "scrolled": false
   },
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "This notebook first generates standardized names from fantasy salary information by querying Basketball-Reference.com, and then merge two datasets while adding fantasy stats based on DraftKings rules. Position information is also modified and added from salary datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-26T09:32:05.924554Z",
     "start_time": "2019-05-26T09:32:05.420122Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import time\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from datetime import datetime\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import utils\n",
    "from constants import DATA_DIR, SECONDS_SLEEP, DF_VARIABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-26T09:32:07.439131Z",
     "start_time": "2019-05-26T09:32:07.435317Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_columns\", 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Fantasy Stats from Boxscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-26T09:32:45.478854Z",
     "start_time": "2019-05-26T09:32:45.465708Z"
    }
   },
   "outputs": [],
   "source": [
    "# Add additional columns for double double (DD) and triple double (TD)\n",
    "# Double digit in two or three of points, rebounds, assists, steals and blocks\n",
    "def add_doubles(df):\n",
    "    dd = [0 for i in range(df.shape[0])]\n",
    "    td = [0 for i in range(df.shape[0])]\n",
    "    \n",
    "    for i in tqdm(range(df.shape[0])):\n",
    "        doubles_count = 0\n",
    "        check_doubles = ['PTS','TRB', 'AST', 'STL', 'BLK']\n",
    "        \n",
    "        for stat in check_doubles:\n",
    "            if df.loc[i, stat] >= 10:\n",
    "                doubles_count += 1\n",
    "        \n",
    "        if doubles_count >= 2:\n",
    "            dd[i] = 1\n",
    "        if doubles_count >= 3:\n",
    "            td[i] = 1\n",
    "   \n",
    "    df['DD'] = dd\n",
    "    df['TD'] = td"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Position Information on Salary Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-26T09:32:47.683228Z",
     "start_time": "2019-05-26T09:32:47.676459Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_name_pos(df):\n",
    "    name_pos = {}\n",
    "    \n",
    "    for name in set(df['Name']):\n",
    "        pos = df.loc[(df['Name']==name) & (df['Pos']!=0), 'Pos'].mode()\n",
    "        if len(pos) != 0:\n",
    "            name_pos[name] = pos[0]\n",
    "    \n",
    "    return name_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-26T09:32:50.268617Z",
     "start_time": "2019-05-26T09:32:50.258772Z"
    }
   },
   "outputs": [],
   "source": [
    "def fill_positions(df):\n",
    "    name_pos = generate_name_pos(df)\n",
    "    \n",
    "    for i in tqdm(range(df.shape[0])):\n",
    "        if df.loc[i, 'Pos'] == 0:\n",
    "            name = df.loc[i, 'Name']\n",
    "            if name in name_pos.keys():\n",
    "                df.loc[i, 'Pos'] = name_pos[name]\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-26T09:32:51.176877Z",
     "start_time": "2019-05-26T09:32:51.169951Z"
    }
   },
   "outputs": [],
   "source": [
    "def add_binary_positions(df):\n",
    "    zeros = [0 for i in range(df.shape[0])]\n",
    "    PG, SG, SF, PF, C = zeros.copy(), zeros.copy(), zeros.copy(), zeros.copy(), zeros.copy()\n",
    "        \n",
    "    for i in range(df.shape[0]):\n",
    "        if 'PG' in df.loc[i,'Pos']:\n",
    "            PG[i] = 1\n",
    "            \n",
    "        elif 'SG' in df.loc[i,'Pos']:\n",
    "            SG[i] = 1\n",
    "            \n",
    "        elif 'SF' in df.loc[i,'Pos']:\n",
    "            SF[i] = 1\n",
    "            \n",
    "        elif 'PF' in df.loc[i,'Pos']:\n",
    "            PF[i] = 1\n",
    "\n",
    "        elif 'C' in df.loc[i,'Pos']:\n",
    "            C[i] = 1\n",
    "\n",
    "            \n",
    "    df['PG'] = PG\n",
    "    df['SG'] = SG\n",
    "    df['SF'] = SF\n",
    "    df['PF'] = PF\n",
    "    df['C'] = C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-13T16:06:50.196829Z",
     "start_time": "2018-03-13T16:06:50.193649Z"
    },
    "collapsed": true
   },
   "source": [
    "### Name Standardization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-26T09:32:53.321615Z",
     "start_time": "2019-05-26T09:32:53.277881Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class NameStandardizer():\n",
    "    # Use the search function on Basketball-Reference.com to generate standard names\n",
    "    def parse_name(self, term, active_years):\n",
    "        search_url = 'https://www.basketball-reference.com/search/search.fcgi?hint=&search={term}&pid=&idx='\n",
    "        name_url = search_url.format(term=term.replace(' ','+'))\n",
    "        name_url = name_url.encode('ascii', 'ignore')\n",
    "        print(name_url)\n",
    "        soup = BeautifulSoup(urlopen(name_url.decode('ASCII')),'lxml')\n",
    "        \n",
    "        #Check if there is ambiguity in the name\n",
    "        if soup.find('h1').get_text() != 'Search Results':\n",
    "            print(soup.find('title').get_text(), soup.find('h1').get_text())\n",
    "            return soup.find('h1').get_text()\n",
    "\n",
    "\n",
    "        elif (soup.find('div', id='players', class_='current') == None):\n",
    "            if (len(term.split(' ')) > 2) or ('.' in term):\n",
    "                #Parse again without periods and with first two names\n",
    "                new_term = ' '.join(term.replace('.','').split(' ')[:2])\n",
    "                return self.parse_name(new_term, active_years)\n",
    "            else:\n",
    "                return np.nan\n",
    "\n",
    "        else:        \n",
    "            items = soup.find('div', id='players', class_='current').find_all('div', class_='search-item-name')\n",
    "            candidates = []\n",
    "\n",
    "            for item in items:\n",
    "                name = item.find('a').get_text()\n",
    "\n",
    "                if '(' not in name:\n",
    "                    candidates.append(name)\n",
    "\n",
    "                else:\n",
    "                    career = name[name.find('(')+1:name.find(')')].split('-')\n",
    "                    if len(career) == 1:\n",
    "                        if int(career[0]) in active_years:\n",
    "                            candidates.append(name[:name.find(' (')])\n",
    "                    else:\n",
    "                        start = int(career[0])\n",
    "                        end = int(career[1])\n",
    "\n",
    "                        for year in active_years: \n",
    "                            if year in range(start, end+1):\n",
    "                                candidates.append(name[:name.find(' (')])\n",
    "                                break\n",
    "\n",
    "            if len(candidates) != 0:\n",
    "                for candidate in candidates:\n",
    "                    if term in candidate:\n",
    "                        return candidate\n",
    "                return candidates[0]\n",
    "\n",
    "            else:\n",
    "                return np.nan\n",
    "            \n",
    "            \n",
    "    def generate_standard_names(self, df, active_years):\n",
    "        names = list(set(df['Name']))\n",
    "        standard_names = []\n",
    "        errors, confusions = [], []\n",
    "        \n",
    "        for i, name in enumerate(tqdm(names)):\n",
    "            standard_name = self.parse_name(name, active_years)\n",
    "            \n",
    "            if name != standard_name:\n",
    "                print(\"{} From {} To {}\".format(i, name, standard_name))\n",
    "                \n",
    "                if standard_name == np.nan:\n",
    "                    errors.append(name)\n",
    "\n",
    "                elif ('G-League Stats' in standard_name) or ('International Stats' in standard_name):\n",
    "                    confusions.append(standard_name)\n",
    "                    \n",
    "                else:\n",
    "                    standard_names.append(standard_name)\n",
    "            else:\n",
    "                standard_names.append(standard_name)\n",
    "            \n",
    "            time.sleep(SECONDS_SLEEP)\n",
    "\n",
    "        return (standard_names, errors, confusions) \n",
    "    \n",
    "    \n",
    "    def standardize_names(self, df, standard_names, active_years):\n",
    "        names = list(set(df['Name']))\n",
    "\n",
    "        df = df.dropna().reset_index(drop=True)\n",
    "\n",
    "        diff = [name for name in names if name not in standard_names]\n",
    "        print('{} names are standardized ...'.format(len(diff)))\n",
    "\n",
    "        names_conversion = {}\n",
    "\n",
    "        for name in tqdm(names):\n",
    "            if name in diff:\n",
    "                names_conversion[name] = self.parse_name(name, active_years)\n",
    "                time.sleep(SECONDS_SLEEP)\n",
    "\n",
    "        for i in range(df.shape[0]):\n",
    "            name = df.loc[i,'Name']\n",
    "            if name in names_conversion.keys():\n",
    "                df.loc[i,'Name'] = names_conversion[name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-25T16:28:09.961055Z",
     "start_time": "2019-05-25T16:28:09.956201Z"
    }
   },
   "source": [
    "### Generate/Load Standardized Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-25T21:02:12.851421Z",
     "start_time": "2019-05-25T21:02:12.836934Z"
    }
   },
   "outputs": [],
   "source": [
    "# Check if standard names are already generated\n",
    "if os.path.exists(os.path.join(DATA_DIR, 'Names', 'standard_names.npy')):\n",
    "    with open(os.path.join(DATA_DIR, 'Names', 'standard_names.npy'), \"rb\") as fp:\n",
    "        standard_names = pickle.load(fp)\n",
    "    \n",
    "    with open(os.path.join(DATA_DIR, 'Names', 'confusions.npy'), \"rb\") as fp:\n",
    "        confusions = pickle.load(fp)\n",
    "    \n",
    "else:\n",
    "    # Generate standard names for all players from names shown in salary information from RotoGuru\n",
    "    df_salary = utils.csv_concatenate(os.path.join(DATA_DIR, 'DKSalary'), nested=True)\n",
    "\n",
    "    # Specify current years to avoid duplication across eras (from 2014 to 2019)\n",
    "    active_years = [2014+i for i in range(6)]\n",
    "\n",
    "    # Takes about 30 mins\n",
    "    standardizer = NameStandardizer()\n",
    "    standard_names, errors, confusions = standardizer.generate_standard_names(df_salary, active_years)\n",
    "\n",
    "    # Create a file containing standardized names\n",
    "    with open(os.path.join(DATA_DIR, 'Names', 'standard_names.npy'), \"wb\") as fp:\n",
    "        pickle.dump(standard_names, fp)\n",
    "\n",
    "    with open(os.path.join(DATA_DIR, 'Names', 'errors.npy'), \"wb\") as fp:\n",
    "        pickle.dump(errors, fp)\n",
    "\n",
    "    with open(os.path.join(DATA_DIR, 'Names', 'confusions.npy'), \"wb\") as fp:\n",
    "        pickle.dump(confusions, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-25T21:02:13.820592Z",
     "start_time": "2019-05-25T21:02:13.812961Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Walter Lemon Jr. International Stats', 'Derrick Walton Jr. G-League Stats', 'C.J. McCollum G-League Stats', 'Sheldon McClellan G-League Stats']\n"
     ]
    }
   ],
   "source": [
    "# Handle edge cases manually as some name searchs return only G-league stats but not NBA records\n",
    "# Cannot be differentiated from players who only played in the G-League at the moment\n",
    "print(confusions)\n",
    "standard_names = standard_names + ['Derrick Walton', 'CJ McCollum', 'Sheldon Mac']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardize Names and Merge Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-25T21:13:36.593423Z",
     "start_time": "2019-05-25T21:02:15.734075Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2018, 2019, 2020]\n",
      "Processing the 2019-20 season ...\n",
      "16 names are standardized ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e491fd6cc34d45dfb15bc8d7958a9ae3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=67), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'https://www.basketball-reference.com/search/search.fcgi?hint=&search=Amir+Coffey&pid=&idx='\n",
      "Amir Coffey Stats | Basketball-Reference.com Amir Coffey\n",
      "b'https://www.basketball-reference.com/search/search.fcgi?hint=&search=Nicolo+Melli&pid=&idx='\n",
      "Nicolò Melli Stats | Basketball-Reference.com Nicolò Melli\n",
      "b'https://www.basketball-reference.com/search/search.fcgi?hint=&search=Louis+Williams&pid=&idx='\n",
      "b'https://www.basketball-reference.com/search/search.fcgi?hint=&search=Zion+Williamson&pid=&idx='\n",
      "Zion Williamson Stats | Basketball-Reference.com Zion Williamson\n",
      "b'https://www.basketball-reference.com/search/search.fcgi?hint=&search=Dewan+Hernandez&pid=&idx='\n",
      "Dewan Hernandez Stats | Basketball-Reference.com Dewan Hernandez\n",
      "b'https://www.basketball-reference.com/search/search.fcgi?hint=&search=Derrick+Walton+Jr.&pid=&idx='\n",
      "Derrick Walton Jr. G-League Stats | Basketball-Reference.com Derrick Walton Jr. G-League Stats\n",
      "b'https://www.basketball-reference.com/search/search.fcgi?hint=&search=Zach+Norvell+Jr.&pid=&idx='\n",
      "b'https://www.basketball-reference.com/search/search.fcgi?hint=&search=Zach+Norvell&pid=&idx='\n",
      "Zach Norvell Stats | Basketball-Reference.com Zach Norvell\n",
      "b'https://www.basketball-reference.com/search/search.fcgi?hint=&search=Jaxson+Hayes&pid=&idx='\n",
      "Jaxson Hayes Stats | Basketball-Reference.com Jaxson Hayes\n",
      "b'https://www.basketball-reference.com/search/search.fcgi?hint=&search=Terence+Davis&pid=&idx='\n",
      "Terence Davis Stats | Basketball-Reference.com Terence Davis\n",
      "b'https://www.basketball-reference.com/search/search.fcgi?hint=&search=Matt+Thomas&pid=&idx='\n",
      "b'https://www.basketball-reference.com/search/search.fcgi?hint=&search=Talen+Horton-Tucker&pid=&idx='\n",
      "Talen Horton-Tucker Stats | Basketball-Reference.com Talen Horton-Tucker\n",
      "b'https://www.basketball-reference.com/search/search.fcgi?hint=&search=Terance+Mann&pid=&idx='\n",
      "Terance Mann Stats | Basketball-Reference.com Terance Mann\n",
      "b'https://www.basketball-reference.com/search/search.fcgi?hint=&search=Nickeil+Alexander-Walker&pid=&idx='\n",
      "Nickeil Alexander-Walker Stats | Basketball-Reference.com Nickeil Alexander-Walker\n",
      "b'https://www.basketball-reference.com/search/search.fcgi?hint=&search=Mfiondu+Kabengele&pid=&idx='\n",
      "Mfiondu Kabengele Stats | Basketball-Reference.com Mfiondu Kabengele\n",
      "b'https://www.basketball-reference.com/search/search.fcgi?hint=&search=Zylan+Cheatham&pid=&idx='\n",
      "Zylan Cheatham Stats | Basketball-Reference.com Zylan Cheatham\n",
      "b'https://www.basketball-reference.com/search/search.fcgi?hint=&search=Oshae+Brissett&pid=&idx='\n",
      "Oshae Brissett Stats | Basketball-Reference.com Oshae Brissett\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "299678774a934d3e9e78d006a52cdd1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=67), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7dad7e78c3614f04b66f159375bc303b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=39), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3 names are standardized ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f80375628c3413fb9c863307ffd56aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=39), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'https://www.basketball-reference.com/search/search.fcgi?hint=&search=Terence+Davis&pid=&idx='\n",
      "Terence Davis Stats | Basketball-Reference.com Terence Davis\n",
      "b'https://www.basketball-reference.com/search/search.fcgi?hint=&search=Nicol+Melli&pid=&idx='\n",
      "Nicolò Melli Stats | Basketball-Reference.com Nicolò Melli\n",
      "b'https://www.basketball-reference.com/search/search.fcgi?hint=&search=Nickeil+Alexander-Walker&pid=&idx='\n",
      "Nickeil Alexander-Walker Stats | Basketball-Reference.com Nickeil Alexander-Walker\n",
      "\n"
     ]
    }
   ],
   "source": [
    "seasons = ['2019-20']\n",
    "active_years = [2018+i for i in range(3)]\n",
    "print(active_years)\n",
    "\n",
    "standardizer = NameStandardizer()\n",
    "\n",
    "for season in seasons:\n",
    "    print('Processing the {} season ...'.format(season))\n",
    "    \n",
    "    # Standardize names for salary information\n",
    "    df_salary = utils.csv_concatenate(os.path.join(DATA_DIR, 'DKSalary', season))\n",
    "    standardizer.standardize_names(df_salary, standard_names, active_years)\n",
    "    fill_positions(df_salary)\n",
    "    \n",
    "    # Standardize names for boxscores\n",
    "    df_games = utils.csv_concatenate(os.path.join(DATA_DIR, 'Boxscores', season))\n",
    "    df_games['FPTS'] = utils.calculate_FPTS(df_games)\n",
    "#     add_doubles(df_games)\n",
    "    df_games = df_games.loc[:, DF_VARIABLES]\n",
    "    standardizer.standardize_names(df_games, standard_names, active_years)\n",
    "    \n",
    "    # Merge two datasets and save to a csv file\n",
    "    df = pd.merge(df_salary.drop('Team', axis=1), df_games, on=['Name', 'Date'], how='inner')\n",
    "    df = df[df['Pos']!=0].sort_values(by=['Date','Team']).reset_index(drop=True)\n",
    "\n",
    "    # Add \"Value\" variable defined as a ratio between FPTS and Salary\n",
    "#     df['Value'] = df['FPTS']/(df['Salary']/1000)\n",
    "#     df['Value'] = df['Value'].replace(np.inf, 0).replace(-np.inf, 0)\n",
    "    \n",
    "    # Add binary positions for later use in EDA and modelling \n",
    "    add_binary_positions(df)\n",
    "    \n",
    "    columns = DF_VARIABLES.copy()\n",
    "    \n",
    "    for i, new_column in zip([1,3,4,43,44,45,46,47], ['Pos','Salary', 'Starter','PG','SG','SF','PF','C']):\n",
    "        columns.insert(i, new_column)\n",
    "\n",
    "    df = df.loc[:, columns]\n",
    "    df.to_csv(os.path.join(DATA_DIR, 'Dataframes', 'Merged','df_{}.csv'.format(season)), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
